{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Course (2024 Spring) Homework 1\n",
    "\n",
    "---\n",
    "\n",
    "## Problem 5. Camera calibration.\n",
    "Camera calibration is the process of determining the intrinsic and extrinsic parameters of a camera. One of the most commonly used methods is proposed by Zhang in 1999. In this problem, let's simply simulate the process of this algorithm.\n",
    "We provide a copy of python code for the simulation of a perspective camera model and a 3D chessboard, which can be used to generate the corner points of chessboard images from different viewpoints. In this way, we can skip the process of corner detection and focus on the calibration processes.\n",
    "\n",
    "1) *Intrinsic parameters calibration.* Please generate 2D-3D correspondences using the provided code. Then use them to estimate the intrinsic parameters of the pre-defined camera. Compare the results with the ground-truth values, and discuss how should we place the chessboard (or the camera) during the calibration to get better results. (15 points)\n",
    "2) *Extrinsic parameters calibration.* Assume that we have captured two images with the **same** chessboard and camera from different viewpoints. However, the detected corner points are somehow noised. We use the 3D coordinates of chessboard as the world coordinates. Please design a method to estimate the extrinsic camera parameters of the two images. For qualitative and quantitative evaluation, please visualize your results by projecting the 3D chessboard corner points onto the two images with the estimated camera parameters, and calculate the reprojection error. (15 points)\n",
    "\n",
    "- Data for extrinsic parameters calibration:\n",
    "  - Files: `data/cv_hw_1_5_correspondences0.txt`, `data/cv_hw_1_5_correspondences1.txt`\n",
    "  - Format: In each row, (x, y, X, Y, Z) are the 2D coordinates of chessboard corner points in image plane and the corressponding 3D coordinates in space.\n",
    "  - Visualization examples: the 2D points are visualized in `data/chessboard0.jpg` and `data/chessboard1.jpg` correspondingly.\n",
    "\n",
    "- Hint:\n",
    "  - Your answer will be graded based on both the performance of the algorithm (in Code blocks) and the completeness of the discussion (in Markdown blocks or the PDF report).\n",
    "  - You can use `cv2.calibrateCamera()` or `cv2.solvePnP` functions. At the same time, please explain the parameters in your report.\n",
    "  - You are also encouraged to write your own code without using `cv2.findHomography()`, which may earn more points.\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple guide to use `CameraModel` and `Chessboard3D`\n",
    "\n",
    "Required environment:\n",
    "- `python 3.8` with `numpy`, `opencv-python` packages.\n",
    "\n",
    "The `CameraModel` class is to simulate a perspective camera.\n",
    "- `CameraModel.project(points3D)`: project 3D points onto the 2D image plane.\n",
    "    - Parameters:\n",
    "        - `points3D`: 3D coordinates of points in 3D space, type `np.ndarray`, size `(N,3)`.\n",
    "    - Returns:\n",
    "        - `points2D`: 2D coordinates of points in image plane, type `np.ndarray`, size `(N,2)`.\n",
    "\n",
    "- `CameraModel.draw(points2D, out_img_path=None)`: draw 2D points and check if they are inside the image.\n",
    "    - Parameters:\n",
    "        - `points2D`: 2D coordinates of points in image plane, type `np.ndarray`, size `(N,2)`.\n",
    "        - `out_img_path`: path to save the output image.\n",
    "    - Returns:\n",
    "        - if `True`: all 2D points are inside the image.\n",
    "        - if `False`: some 2D points are outside the image.\n",
    "\n",
    "- `CameraModel.move_<axis_name>_plus(step)`: move the camera along `axis_name` in world coordinates.\n",
    "    - axis_name: `x_axis`, `y_axis`, `z_axis`\n",
    "    - Parameters:\n",
    "        - `step`: moving distance.\n",
    "\n",
    "- `CameraModel.rotate_<angel_name>(degree)`: rotate the camera in camera coordinates.\n",
    "    - camera coordinates: x = right, y = down, z = view direction. (right-hand system)\n",
    "    - angel_name:\n",
    "        - `pitch`: clockwise along the x-axis\n",
    "        - `yaw`: clockwise along the y-axis\n",
    "        - `roll`: clockwise along the z-axis\n",
    "    - Parameters:\n",
    "        - `degree`: rotation angle in degree, type `float`.\n",
    "\n",
    "- `CameraModel.reset()`: reset the position and rotation of camera.\n",
    "\n",
    "- `CameraModel.set_<K/R/T>(K/R/T)`: reset the parameters of camera with known values.\n",
    "\n",
    "\n",
    "The `Chessboard3D` class is to simulate a simple 3D chessboard.\n",
    "- `Chessboard3D.return_points()`: get the 3D coordinates of corner points.\n",
    "    - Returns:\n",
    "        - points3D: np.ndarray, (N,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CameraModel\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class CameraModel(object):\n",
    "    \"\"\" a simple perspective camera with controllable intrinsic and extrinsic parameters.\n",
    "    \"\"\"\n",
    "    dft_configs = {\n",
    "        \"fx\": 200,\n",
    "        \"fy\": 200,\n",
    "        \"cx\": 256,\n",
    "        \"cy\": 256,\n",
    "        \"pitch\": 0, # degrees\n",
    "        \"yaw\": 0, # degrees\n",
    "        \"roll\": 0, # degrees\n",
    "        \"x\": 0, # translation\n",
    "        \"y\": 0,\n",
    "        \"z\": 10,\n",
    "    }\n",
    "    def __init__(self, configs={}) -> None:\n",
    "        self.configs = {**self.dft_configs, **configs}\n",
    "        self.fx = self.configs[\"fx\"]\n",
    "        self.fy = self.configs[\"fy\"]\n",
    "        self.cx = self.configs[\"cx\"]\n",
    "        self.cy = self.configs[\"cy\"]\n",
    "        self.K = np.array([[self.fx, 0, self.cx], [0, self.fy, self.cy], [0, 0, 1]])\n",
    "\n",
    "        self.pitch = self.configs[\"pitch\"]\n",
    "        self.yaw = self.configs[\"yaw\"]\n",
    "        self.roll = self.configs[\"roll\"]\n",
    "        self.R = self._get_rotation_matrix(self.pitch, self.yaw, self.roll)\n",
    "\n",
    "        self.x = self.configs[\"x\"]\n",
    "        self.y = self.configs[\"y\"]\n",
    "        self.z = self.configs[\"z\"]\n",
    "        self.T = np.array([self.x, self.y, self.z])\n",
    "\n",
    "    def show_K(self):\n",
    "        print(f\"K: {self.K}\")\n",
    "    \n",
    "    def show_R(self):\n",
    "        print(f\"R: {self.R}\")\n",
    "\n",
    "    def show_T(self):\n",
    "        print(f\"T: {self.T}\")\n",
    "\n",
    "    def _get_rotation_matrix(self, pitch, yaw, roll):\n",
    "        pitch = np.deg2rad(pitch)\n",
    "        yaw = np.deg2rad(yaw)\n",
    "        roll = np.deg2rad(roll)\n",
    "        Rx = np.array([[1, 0, 0], [0, np.cos(pitch), -np.sin(pitch)], [0, np.sin(pitch), np.cos(pitch)]])\n",
    "        Ry = np.array([[np.cos(yaw), 0, np.sin(yaw)], [0, 1, 0], [-np.sin(yaw), 0, np.cos(yaw)]])\n",
    "        Rz = np.array([[np.cos(roll), -np.sin(roll), 0], [np.sin(roll), np.cos(roll), 0], [0, 0, 1]])\n",
    "        \n",
    "        return Rz @ Ry @ Rx\n",
    "\n",
    "    def project(self, points3D):\n",
    "        \"\"\" Project 3D points to 2D\n",
    "        Args:\n",
    "            points3D: 3D points, numpy array of shape (N, 3)\n",
    "        \"\"\"\n",
    "        points3D = points3D.reshape(-1, 3)\n",
    "        points3D = points3D.T\n",
    "        points_ = self.R @ points3D + self.T.reshape(-1, 1)\n",
    "        points_ = self.K @ points_\n",
    "        points2D = points_ / points_[2, :]\n",
    "        \n",
    "        return points2D[:2, :].T # (N, 2)\n",
    "    \n",
    "    def draw(self, points, out_img_path=None, vbose=False):\n",
    "        \"\"\" Draw 2D points on image\n",
    "        Args:\n",
    "            points: 2D points, numpy array of shape (N, 2)\n",
    "        \"\"\"\n",
    "        img_W = 2*self.cx\n",
    "        img_H = 2*self.cy\n",
    "        img = np.zeros((img_H, img_W, 3), dtype=np.uint8)\n",
    "\n",
    "        point_num = points.shape[0]\n",
    "        outside_img_count = 0\n",
    "        for point in points:\n",
    "            x, y = point\n",
    "            x, y = int(x), int(y)\n",
    "            if 0 <= x < img_W and 0 <= y < img_H:\n",
    "                img = cv2.circle(img, (x, y), 5, (0, 255, 0), -1)\n",
    "            else:\n",
    "                outside_img_count += 1\n",
    "                if vbose:\n",
    "                    print(f\"Point ({x}, {y}) is outside the image\")\n",
    "        if vbose:\n",
    "            print(f\"Outside image count: {outside_img_count}, while total points: {point_num}\")\n",
    "\n",
    "        if out_img_path:\n",
    "            cv2.imwrite(out_img_path, img)\n",
    "        \n",
    "        if outside_img_count > 0: return False\n",
    "        return True\n",
    "\n",
    "    def move_x_axis_plus(self, step):\n",
    "        self.x += step\n",
    "        self.T = np.array([self.x, self.y, self.z])\n",
    "    \n",
    "    def move_y_axis_plus(self, step):\n",
    "        self.y += step\n",
    "        self.T = np.array([self.x, self.y, self.z])\n",
    "\n",
    "    def move_z_axis_plus(self, step):\n",
    "        self.z += step\n",
    "        self.T = np.array([self.x, self.y, self.z])\n",
    "    \n",
    "    def rotate_pitch_plus(self, degree):\n",
    "        self.pitch += degree\n",
    "        self.R = self._get_rotation_matrix(self.pitch, self.yaw, self.roll)\n",
    "\n",
    "    def rotate_yaw_plus(self, degree):\n",
    "        self.yaw += degree\n",
    "        self.R = self._get_rotation_matrix(self.pitch, self.yaw, self.roll)\n",
    "    \n",
    "    def rotate_roll_plus(self, degree):\n",
    "        self.roll += degree\n",
    "        self.R = self._get_rotation_matrix(self.pitch, self.yaw, self.roll)\n",
    "\n",
    "    def reset(self):\n",
    "        self.x = self.configs[\"x\"]\n",
    "        self.y = self.configs[\"y\"]\n",
    "        self.z = self.configs[\"z\"]\n",
    "        self.T = np.array([self.x, self.y, self.z])\n",
    "\n",
    "        self.pitch = self.configs[\"pitch\"]\n",
    "        self.yaw = self.configs[\"yaw\"]\n",
    "        self.roll = self.configs[\"roll\"]\n",
    "        self.R = self._get_rotation_matrix(self.pitch, self.yaw, self.roll)\n",
    "    \n",
    "    def set_K(self, intrinsic_matrix):\n",
    "        self.K = intrinsic_matrix\n",
    "    \n",
    "    def set_R(self, rotation_matrix):\n",
    "        R = rotation_matrix\n",
    "        \n",
    "        # Extract pitch (rotation around x-axis)\n",
    "        pitch = np.arctan2(R[2, 1], R[2, 2])\n",
    "        # Extract yaw (rotation around y-axis)\n",
    "        yaw = np.arctan2(-R[2, 0], np.sqrt(R[2, 1]**2 + R[2, 2]**2))\n",
    "        # Extract roll (rotation around z-axis)\n",
    "        roll = np.arctan2(R[1, 0], R[0, 0])\n",
    "\n",
    "        # Convert radians to degrees\n",
    "        self.pitch = np.degrees(pitch)\n",
    "        self.yaw = np.degrees(yaw)\n",
    "        self.roll = np.degrees(roll)\n",
    "        self.R = R\n",
    "    \n",
    "    def set_T(self, translation):\n",
    "        self.T = translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chessboard3D\n",
    "\n",
    "class Chessboard3D(object):\n",
    "    \"\"\" a simple 3D chessboard, providing the coordinates of corner points.\n",
    "    \"\"\"\n",
    "    dft_configs = {\n",
    "        \"square_size\": 1,\n",
    "        \"rows\": 8,\n",
    "        \"cols\": 8,\n",
    "        \"z_plane\": 0,\n",
    "    }\n",
    "\n",
    "    def __init__(self, configs={}) -> None:\n",
    "        self.configs = {**self.dft_configs, **configs}\n",
    "        self.square_size = self.configs[\"square_size\"]\n",
    "        self.rows = self.configs[\"rows\"]\n",
    "        self.cols = self.configs[\"cols\"]\n",
    "        self.z_plane = self.configs[\"z_plane\"]\n",
    "        self.points = self._generate_points()\n",
    "    \n",
    "    def _generate_points(self):\n",
    "        points = []\n",
    "        for row in range(self.rows):\n",
    "            for col in range(self.cols):\n",
    "                points.append([col*self.square_size, row*self.square_size, self.z_plane])\n",
    "        return np.array(points) # (N, 3)\n",
    "\n",
    "    def return_points(self):\n",
    "        \"\"\" get corner points of the 3D chessboard\n",
    "        Returns:\n",
    "            points3D: np.ndarray, (N,3)\n",
    "        \"\"\"\n",
    "        return self.points"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Intrinsic parameters calibration\n",
    "\n",
    "Steps:\n",
    "1) Use `CameraModel` and `Chessboard3D` (with the default configuration) to generate 2D-3D correspondences.\n",
    "2) Write code to estimate the camera intrinsic parameters.\n",
    "3) Compare your results with the ground-truth values (in `CameraModel.dft_configs`).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: generate 2D-3D correspondences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create class objects\n",
    "camera = CameraModel()\n",
    "chessboard = Chessboard3D()\n",
    "\n",
    "# get the 3D coordinates in chessboard\n",
    "coordinate_3D = chessboard.return_points()\n",
    "# project 3D coordinates to 2D\n",
    "projection_2D = camera.project(coordinate_3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2&3: estimate the camera intrinsic parameters and compare results with the ground-truth values\n",
    "\n",
    "* Here, we firstly use `cv2.calibrateCamera()` to estimate the camera intrinsic parameters. The `cv2.calibrateCamera` function in OpenCV is used to compute the camera calibration and distortion coefficients given a set of 3D real-world points and their corresponding 2D image points. The function prototype is:\n",
    "\n",
    "`retval, cameraMatrix, distCoeffs, rvecs, tvecs = cv2.calibrateCamera(objectPoints, imagePoints, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, flags[, criteria]]]])`\n",
    "\n",
    "* Parameter explanation:\n",
    "    * `objectPoints`: A list of arrays of the 3D points in the real world. Each element of the list should be of the shape (N, 1, 3) or (1, N, 3) for N points in each scene.\n",
    "    * `imagePoints`: A list of arrays of the corresponding 2D points in the image. Each element of the list should be of the shape (N, 1, 2) or (1, N, 2), matching the objectPoints.\n",
    "    * `imageSize`: Size of the image used only to initialize the intrinsic camera matrix. It should be in the format of (width, height).\n",
    "    * `distCoeffs`: Input/output vector of distortion coefficients.\n",
    "* Return:\n",
    "    * `cameraMatrix`: Input/output 2D array of the camera matrix\n",
    "    $\n",
    "    \\left[\n",
    "    \\begin{matrix}\n",
    "        f_x & 0 & c_x \\\\\n",
    "        0 & f_y & c_y \\\\\n",
    "        0 & 0 & 1\n",
    "    \\end{matrix}\n",
    "    \\right]\n",
    "    $.\n",
    "    * `distCoeffs`: Input/output vector of distortion coefficients.\n",
    "    * `rvecs`: Output vector of rotation vectors (Rodrigues) estimated for each pattern view.\n",
    "    * `tvecs`: Output vector of translation vectors estimated for each pattern view.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.80066270e+19 0.00000000e+00 2.55527956e+02]\n",
      " [0.00000000e+00 2.80066270e+19 2.55551631e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "K: [[200   0 256]\n",
      " [  0 200 256]\n",
      " [  0   0   1]]\n"
     ]
    }
   ],
   "source": [
    "# The image size defined in CameraModel.draw() is (cy*2)*(cx*2)\n",
    "image_size = (256*2, 256*2) \n",
    "# calibrateCamera() needs the input be float32, and shape (1, N, 3) and (1, N, 2)\n",
    "ret, cameraMatrix, distCoeffs, rvecs, tvecs = cv2.calibrateCamera([coordinate_3D.astype('float32')], [projection_2D.astype('float32')], image_size, None, None)\n",
    "print(cameraMatrix)\n",
    "camera.show_K()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can see that in the return matrix focal length is too large, actually infinite. The reason is due to the 0 rotation.  During the calculation process, matrix elements such as $B_{11}$ is 0, then we induce the infinity focal length. It remains us to place the camera with some rotation in different directions.\n",
    "\n",
    "![Formula of matrix B](./fig1.png)\n",
    "\n",
    "* We give a rotation to camera, then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: [[200   0 256]\n",
      " [  0 200 256]\n",
      " [  0   0   1]]\n",
      "One homography with some rotation \n",
      "[[199.47669174   0.         255.50072632]\n",
      " [  0.         199.49409443 255.49925937]\n",
      " [  0.           0.           1.        ]]\n"
     ]
    }
   ],
   "source": [
    "delta_rotation = 1\n",
    "camera.rotate_pitch_plus(delta_rotation)\n",
    "camera.rotate_yaw_plus(delta_rotation)\n",
    "camera.rotate_roll_plus(delta_rotation)\n",
    "\n",
    "# project 3D coordinates to 2D\n",
    "projection_2D_1 = camera.project(coordinate_3D)\n",
    "# calibrateCamera() needs the input be float32, and shape (1, N, 3) and (1, N, 2)\n",
    "ret, cameraMatrix, distCoeffs, rvecs, tvecs = cv2.calibrateCamera([coordinate_3D.astype('float32')], [projection_2D_1.astype('float32')], image_size, None, None)\n",
    "camera.show_K()\n",
    "print(\"One homography with some rotation \")\n",
    "print(cameraMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To get accurate result, we need more 2D-3D correspondances groups, i.e. more homography matrix. Let $n$ be the number of homography matrices. In the paper, we need to solve $b$ in the equation $Vb = 0$, where $V$ is a $2n\\times 6$ matrix. If $n \\geq 3$, we will have in general a unique solution $b$ defined up to a scale factor.\n",
    "If $n = 2$, we can impose the skewless constraint $c = 0$, which is added as an additional equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: [[200   0 256]\n",
      " [  0 200 256]\n",
      " [  0   0   1]]\n",
      "2 homography: \n",
      "[[200.00678335   0.         255.99933648]\n",
      " [  0.         200.00679381 256.0003592 ]\n",
      " [  0.           0.           1.        ]]\n",
      "3 homography: \n",
      "[[199.99996534   0.         256.00008299]\n",
      " [  0.         199.99996223 255.99999008]\n",
      " [  0.           0.           1.        ]]\n"
     ]
    }
   ],
   "source": [
    "delta_rotation = 3\n",
    "camera.rotate_pitch_plus(delta_rotation)\n",
    "camera.rotate_yaw_plus(delta_rotation)\n",
    "camera.rotate_roll_plus(delta_rotation)\n",
    "\n",
    "# project 3D coordinates to 2D\n",
    "projection_2D_2 = camera.project(coordinate_3D)\n",
    "\n",
    "delta_rotation = 10\n",
    "camera.rotate_pitch_plus(delta_rotation)\n",
    "camera.rotate_yaw_plus(delta_rotation)\n",
    "camera.rotate_roll_plus(delta_rotation)\n",
    "\n",
    "# project 3D coordinates to 2D\n",
    "projection_2D_3 = camera.project(coordinate_3D)\n",
    "\n",
    "camera.show_K()\n",
    "\n",
    "ret, cameraMatrix, distCoeffs, rvecs, tvecs = cv2.calibrateCamera([coordinate_3D.astype('float32')]*2, [projection_2D_1.astype('float32'), projection_2D_2.astype('float32')], image_size, None, None)\n",
    "print(\"2 homography: \")\n",
    "print(cameraMatrix)\n",
    "\n",
    "ret, cameraMatrix, distCoeffs, rvecs, tvecs = cv2.calibrateCamera([coordinate_3D.astype('float32')]*3, [projection_2D_1.astype('float32'), projection_2D_2.astype('float32'), projection_2D_3.astype('float32')], image_size, None, None)\n",
    "print(\"3 homography: \")\n",
    "print(cameraMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since the truth skewless constraint of $K$ is zero, so we can get a basically accurate result just using 2 homography matrices.\n",
    "\n",
    "* Besides, we write own code to implement Zhang's calibration algorithm as the following. We can see that result has minor errors in skewless constraint and other parameters but basically correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.00000480e+02 2.33819990e-01 2.55999904e+02]\n",
      " [0.00000000e+00 2.00000475e+02 2.56000124e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "def generate_v_ij(H_stack, i, j):\n",
    "    \"\"\"\n",
    "    Generate intrinsic orthogonality constraints.\n",
    "    \"\"\"\n",
    "    N = H_stack.shape[0]\n",
    "    v_ij = np.zeros((N, 6))\n",
    "    v_ij[:, 0] = H_stack[:, 0, i] * H_stack[:, 0, j]\n",
    "    v_ij[:, 1] = H_stack[:, 0, i] * H_stack[:, 1, j] + H_stack[:, 1, i] * H_stack[:, 0, j]\n",
    "    v_ij[:, 2] = H_stack[:, 1, i] * H_stack[:, 1, j]\n",
    "    v_ij[:, 3] = H_stack[:, 2, i] * H_stack[:, 0, j] + H_stack[:, 0, i] * H_stack[:, 2, j]\n",
    "    v_ij[:, 4] = H_stack[:, 2, i] * H_stack[:, 1, j] + H_stack[:, 1, i] * H_stack[:, 2, j]\n",
    "    v_ij[:, 5] = H_stack[:, 2, i] * H_stack[:, 2, j]\n",
    "    return v_ij\n",
    "\n",
    "def svd_solve(A):\n",
    "    \"\"\"利用SVD求解齐次方程\"\"\"\n",
    "    U, S, V_t = np.linalg.svd(A)\n",
    "    # S已经从大到小排列了，方程解即奇异值最小的那列右奇异向量\n",
    "    return V_t[np.argmin(S)]\n",
    "\n",
    "def calc_homography(objectPoints, imagePoints):\n",
    "    Hs = []\n",
    "    for i in range(len(objectPoints)):\n",
    "        A = []\n",
    "        for j in range(len(objectPoints[i])):\n",
    "            # convert to homogeneous coordinates\n",
    "            x_i = np.append(objectPoints[i][j][:2], 1)\n",
    "            # omega is 1\n",
    "            A_i1 = np.hstack((np.zeros((3)), -1*x_i, imagePoints[i][j][1]*x_i))\n",
    "            A_i2 = np.hstack((x_i, np.zeros((3)), -1*imagePoints[i][j][0]*x_i))\n",
    "            A.append(A_i1)\n",
    "            A.append(A_i2)\n",
    "        A = np.array(A)\n",
    "        Hs.append(svd_solve(A).reshape(3, 3))\n",
    "    return Hs\n",
    "\n",
    "def calc_intrinsic(objectPoints, imagePoints):\n",
    "    Hs = calc_homography(objectPoints, imagePoints)\n",
    "    N = len(Hs)\n",
    "    H_stack = np.zeros((N, 3, 3))\n",
    "    for idx, H in enumerate(Hs):\n",
    "        H_stack[idx] = H\n",
    "    # 注：实现时候我们-1\n",
    "    v_00 = generate_v_ij(H_stack, i=0, j=0)\n",
    "    v_01 = generate_v_ij(H_stack, i=0, j=1)\n",
    "    v_11 = generate_v_ij(H_stack, i=1, j=1)\n",
    "\n",
    "    V = np.zeros((2 * N, 6))\n",
    "    V[:N] = v_01\n",
    "    V[N:] = v_00 - v_11\n",
    "    b = svd_solve(V)\n",
    "\n",
    "    B11, B12, B22, B13, B23, B33 = b\n",
    "\n",
    "    # calculate K\n",
    "    v0 = (B12 * B13 - B11 * B23) / (B11 * B22 - B12 ** 2)\n",
    "    lambda_ = B33 - (B13 ** 2 + v0 *(B12 * B13 - B11 * B23)) / B11\n",
    "    alpha = np.sqrt(lambda_ / B11)\n",
    "    beta = np.sqrt(lambda_ * B11 / (B11 * B22 - B12 **2))\n",
    "    c = -1 * B12 * alpha ** 2 * beta / lambda_\n",
    "    u0 = c * v0 / alpha - B13 * alpha ** 2 / lambda_\n",
    "\n",
    "    K = np.array([[alpha, lambda_, u0],\n",
    "                   [0.,    beta,  v0],\n",
    "                   [0.,    0.,    1.]])\n",
    "    return K\n",
    "\n",
    "test_K = calc_intrinsic([coordinate_3D.astype('float32')]*3, [projection_2D_1.astype('float32'), projection_2D_2.astype('float32'), projection_2D_3.astype('float32')])\n",
    "print(test_K)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Extrinsic parameters calibration\n",
    "\n",
    "Steps:\n",
    "1) Load 2D-3D correspondences from `data/cv_hw_1_5_correspondences0.txt` and `data/cv_hw_1_5_correspondences1.txt`.\n",
    "2) Write code to calibrate the extrinsic camera parameters.\n",
    "3) Visualize your results by projecting the chessboard corner points onto image planes.\n",
    "4) Calculate the reprojection error and analysis the results.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: load 2D-3D correspondences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here.\n",
    "data0 = np.loadtxt('data/cv_hw_1_5_correspondences0.txt')\n",
    "data1 = np.loadtxt('data/cv_hw_1_5_correspondences1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: calibrate the extrinsic camera parameters\n",
    "\n",
    "* In this step, we assume that we already know the instrinsic camera parameters, i.e. $K$ is known. We firstly use `cv2.solvePnP` function in OpenCV is utilized for estimating the pose of an object by finding the rotation and translation vectors that transform 3D points from the object coordinate frame to the camera coordinate frame. The function prototype is:\n",
    "\n",
    "`retval, rvec, tvec = cv2.solvePnP(objectPoints, imagePoints, cameraMatrix, distCoeffs[, rvec[, tvec[, useExtrinsicGuess[, flags]]]])`\n",
    "\n",
    "* Parameter explanation:\n",
    "    * `objectPoints`: Array of object points in the object coordinate space. It is a floating-point array of shape (N, 1, 3), (1, N, 3), or (N, 3), where N is the number of points.\n",
    "    * `imagePoints`: Array of corresponding image points. It is a floating-point array of shape (N, 1, 2), (1, N, 2), or (N, 2).\n",
    "    * `cameraMatrix`: The camera's intrinsic parameters matrix\n",
    "    $\n",
    "    \\left[\n",
    "    \\begin{matrix}\n",
    "        f_x & 0 & c_x \\\\\n",
    "        0 & f_y & c_y \\\\\n",
    "        0 & 0 & 1\n",
    "    \\end{matrix}\n",
    "    \\right]\n",
    "    $.\n",
    "    * `distCoeffs`: Array of the camera's distortion coefficients. If the camera is undistorted or distortion has been corrected, you can pass None or an empty array.\n",
    "* Output:\n",
    "    * `rvec`: Output rotation vector that, together with tvec, transforms 3D points from the object coordinate system to the camera coordinate system. It can be initialized to provide an estimation to enhance speed and accuracy.\n",
    "    * `tvec`: Output translation vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation matrix:\n",
      "the truth value:\n",
      "[[ 0.99969541 -0.01714521  0.01775168]\n",
      " [ 0.01744975  0.99970073 -0.01714521]\n",
      " [-0.01745241  0.01744975  0.99969541]]\n",
      "the caculated value:\n",
      "[[ 0.99969541 -0.01714521  0.01775168]\n",
      " [ 0.01744975  0.99970073 -0.01714521]\n",
      " [-0.01745241  0.01744975  0.99969541]]\n",
      "Translation vector:\n",
      "the truth value:  [ 0  0 10]\n",
      "the caculated value:  [-6.26430683e-10 -4.17025181e-10  9.99999999e+00]\n"
     ]
    }
   ],
   "source": [
    "# already known the intrinsic matrix\n",
    "K = np.array([[200, 0, 256], [0, 200, 256], [0, 0, 1]])\n",
    "\n",
    "(success, rotation_vector, translation_vector) = cv2.solvePnP(np.array([coordinate_3D], dtype=np.double), np.array([projection_2D_1], dtype=np.double), K, distCoeffs = None,flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "\n",
    "# transfer the rotation_vector to rotation matrix\n",
    "rotation_matrix = cv2.Rodrigues(rotation_vector)[0]\n",
    "\n",
    "print(\"Rotation matrix:\")\n",
    "print(\"the truth value:\")\n",
    "print(camera._get_rotation_matrix(1,1,1))\n",
    "print(\"the caculated value:\")\n",
    "print(rotation_matrix)\n",
    "\n",
    "print(\"Translation vector:\")\n",
    "print(\"the truth value: \", camera.T)\n",
    "print(\"the caculated value: \", translation_vector.reshape(3,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We write own code to get the extrinsic parameters, it works well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation matrix:\n",
      "the truth value:\n",
      "[[ 0.99969541 -0.01714521  0.01775168]\n",
      " [ 0.01744975  0.99970073 -0.01714521]\n",
      " [-0.01745241  0.01744975  0.99969541]]\n",
      "the caculated value:\n",
      "[[ 0.99969541 -0.01714521  0.01775168]\n",
      " [ 0.01744975  0.99970073 -0.01714521]\n",
      " [-0.01745241  0.01744975  0.99969541]]\n",
      "Translation vector:\n",
      "the truth value:  [ 0  0 10]\n",
      "the caculated value:  [-6.92779167e-14 -3.01980663e-14  1.00000000e+01]\n"
     ]
    }
   ],
   "source": [
    "# already known the intrinsic matrix\n",
    "K = np.array([[200, 0, 256], [0, 200, 256], [0, 0, 1]])\n",
    "\n",
    "def calc_extrinsic(objectPoints, imagePoints, intrinsic_matrix):\n",
    "    '''\n",
    "    objectPoints: 1*N*3 array\n",
    "    imagePoints: 1*N*2 array\n",
    "    intrinsic_matrix: 3*3 matrix\n",
    "    '''\n",
    "    # calculate the homography\n",
    "    homography_matrix = calc_homography(objectPoints, imagePoints)[0]\n",
    "    h1 = homography_matrix[:, 0]\n",
    "    h2 = homography_matrix[:, 1]\n",
    "    h3 = homography_matrix[:, 2]\n",
    "    lambda_ = 1 / np.linalg.norm(np.linalg.inv(intrinsic_matrix) @ h1.T)\n",
    "    r1 = lambda_ * np.linalg.inv(intrinsic_matrix) @ h1.T\n",
    "    r2 = lambda_ * np.linalg.inv(intrinsic_matrix) @ h2.T\n",
    "    r3 = np.cross(r1.reshape(3,), r2.reshape(3,))\n",
    "    t = lambda_ * np.linalg.inv(intrinsic_matrix) @ h3.T\n",
    "    return np.vstack((r1, r2, r3)).T, t\n",
    "\n",
    "R, T = calc_extrinsic([coordinate_3D], [projection_2D_1], K)\n",
    "\n",
    "print(\"Rotation matrix:\")\n",
    "print(\"the truth value:\")\n",
    "print(camera._get_rotation_matrix(1,1,1))\n",
    "print(\"the caculated value:\")\n",
    "print(R)\n",
    "\n",
    "print(\"Translation vector:\")\n",
    "print(\"the truth value: \", camera.T)\n",
    "print(\"the caculated value: \", T.reshape(3,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To verify the correction of `cv2.solvePnP` and our code, we test the data generated from the ideal camera model. Now we calculate the extrinsic parameters for loaded 2D-3D correspondances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correspondances0:\n",
      "rotation matrix:\n",
      "[[ 1.00000000e+00 -2.48270526e-14  5.62436895e-13]\n",
      " [ 4.84003700e-13  1.00000000e+00  6.67797555e-14]\n",
      " [-5.62436895e-13 -6.67797555e-14  1.00000000e+00]]\n",
      "translation vector:  [1.86517468e-13 2.89546165e-13 1.00000000e+01]\n",
      "Correspondances1:\n",
      "rotation matrix:\n",
      "[[-9.64941363e-01  6.80376168e-02  2.53074663e-01]\n",
      " [ 3.63088875e-06 -9.64217060e-01  2.57589879e-01]\n",
      " [ 2.62465550e-01  2.48442400e-01  9.30412677e-01]]\n",
      "translation vector:  [  4.99328035   4.99217421 -10.00280654]\n"
     ]
    }
   ],
   "source": [
    "R0, T0 = calc_extrinsic([data0[:, 2:]], [data0[:, :2]], K)\n",
    "R1, T1 = calc_extrinsic([data1[:, 2:]], [data1[:, :2]], K)\n",
    "\n",
    "print(\"Correspondances0:\")\n",
    "print(\"rotation matrix:\")\n",
    "print(R0)\n",
    "print(\"translation vector: \", T0)\n",
    "\n",
    "print(\"Correspondances1:\")\n",
    "print(\"rotation matrix:\")\n",
    "print(R1)\n",
    "print(\"translation vector: \", T1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera0 = CameraModel()\n",
    "camera0.R = R0\n",
    "camera0.T = T0\n",
    "# get the projection points using the estimated camera parameters and draw\n",
    "camera0.draw(camera0.project(data0[:, 2:]), 'test_chessboard0.jpg')\n",
    "\n",
    "camera1 = CameraModel()\n",
    "camera1.R = R1\n",
    "camera1.T = T1\n",
    "# get the projection points using the estimated camera parameters and draw\n",
    "camera1.draw(camera1.project(data1[:, 2:]), 'test_chessboard1.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: calculate the reprojection error and analysis the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reprojection error of correspondances0 is:  4.2300235179588005e-19\n",
      "The reprojection error of correspondances1 is:  28.646919039094787\n"
     ]
    }
   ],
   "source": [
    "reprojection_error0 = np.sum((camera0.project(data0[:, 2:])-data0[:, :2])**2)\n",
    "reprojection_error1 = np.sum((camera1.project(data1[:, 2:])-data1[:, :2])**2)\n",
    "\n",
    "print('The reprojection error of correspondances0 is: ', reprojection_error0)\n",
    "print('The reprojection error of correspondances1 is: ', reprojection_error1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can see that the reprojection error of correspondances0 is 0 and correspondances1 is large. We can suppose that points of correspondances0 have accurate coordinates and points of correspondances1 have noisy coordinates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6fc47664f1878ff2ee966f01ca1e9f4805d933244fdd0f9b4907ae56b059aef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
